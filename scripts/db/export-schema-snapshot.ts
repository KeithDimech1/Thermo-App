#!/usr/bin/env npx tsx
/**
 * Export database schema snapshot for living documentation
 * Generates bones-only schema (tables, columns, constraints - no indexes, triggers, etc.)
 */

import { query, closePool } from '../../lib/db/connection'
import * as fs from 'fs'
import * as path from 'path'

async function exportSchemaSnapshot() {
  const timestamp = new Date().toISOString().replace('T', ' ').substring(0, 19)

  console.log('ðŸ“Š Exporting database schema snapshot...')

  try {
    // Get all table definitions
    const tables = await query<{ tablename: string }>(`
      SELECT tablename
      FROM pg_tables
      WHERE schemaname = 'public'
      ORDER BY tablename
    `)

    const schemaLines: string[] = [
      '-- Database Schema Snapshot',
      `-- Generated: ${timestamp}`,
      '-- Database: postgres (Supabase)',
      '-- Generated by: /bigtidy living documentation system',
      ''
    ]

    // For each table, get CREATE TABLE statement
    for (const { tablename } of tables) {
      // Get columns
      const columns = await query<{
        column_name: string
        data_type: string
        character_maximum_length: number | null
        is_nullable: string
        column_default: string | null
      }>(`
        SELECT
          column_name,
          data_type,
          character_maximum_length,
          is_nullable,
          column_default
        FROM information_schema.columns
        WHERE table_schema = 'public' AND table_name = $1
        ORDER BY ordinal_position
      `, [tablename])

      schemaLines.push(`CREATE TABLE public.${tablename} (`)

      const columnDefs = columns.map(col => {
        let def = `    ${col.column_name} ${col.data_type}`

        if (col.character_maximum_length) {
          def += `(${col.character_maximum_length})`
        }

        if (col.data_type === 'numeric' && col.column_default) {
          // Extract precision/scale from default if available
          const match = col.column_default.match(/numeric\((\d+),(\d+)\)/)
          if (match) {
            def = `    ${col.column_name} numeric(${match[1]},${match[2]})`
          }
        }

        if (col.is_nullable === 'NO') {
          def += ' NOT NULL'
        }

        if (col.column_default && !col.column_default.includes('nextval')) {
          def += ` DEFAULT ${col.column_default}`
        }

        return def
      })

      schemaLines.push(columnDefs.join(',\n'))
      schemaLines.push(');')
      schemaLines.push('')
    }

    const schemaContent = schemaLines.join('\n')

    // Save to readme/database/
    const outputPath = path.join(process.cwd(), 'readme', 'database', '.schema-snapshot.sql')
    const previousPath = path.join(process.cwd(), 'readme', 'database', '.schema-previous.sql')

    // Backup previous snapshot
    if (fs.existsSync(outputPath)) {
      fs.copyFileSync(outputPath, previousPath)
      console.log('âœ“ Backed up previous schema snapshot')
    }

    // Write new snapshot
    fs.writeFileSync(outputPath, schemaContent)
    console.log(`âœ“ Schema snapshot saved to ${outputPath}`)
    console.log(`âœ“ Exported ${tables.length} tables`)

    return outputPath

  } catch (error) {
    console.error('âŒ Error exporting schema:', error)
    throw error
  } finally {
    await closePool()
  }
}

// Run if called directly
if (require.main === module) {
  exportSchemaSnapshot()
    .then(() => process.exit(0))
    .catch(() => process.exit(1))
}

export { exportSchemaSnapshot }
